{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "299aaa9a",
   "metadata": {},
   "source": [
    "# 새로운 제스처 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f87d48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time, os\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 인식할 동작 목록 정의\n",
    "actions = ['good', 'bad', 'four', 'five']\n",
    "\n",
    "# 각 시퀀스의 길이와 각 동작의 지속 시간 정의\n",
    "seq_length = 30\n",
    "secs_for_action = 30\n",
    "\n",
    "# MediaPipe hands 모델 초기화\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "# 웹캠 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 데이터셋을 저장할 디렉토리 생성\n",
    "created_time = int(time.time())\n",
    "os.makedirs('dataset', exist_ok=True)\n",
    "\n",
    "# 각 동작에 대한 데이터를 수집하기 위한 루프\n",
    "while cap.isOpened():\n",
    "    for idx, action in enumerate(actions):\n",
    "        data = [] # 현재 동작에 대한 데이터를 저장할 리스트\n",
    "        \n",
    "        # 웹캠에서 프레임을 읽어옴\n",
    "        ret, img = cap.read()\n",
    "\n",
    "        img = cv2.flip(img, 1) # 이미지를 좌우로 뒤집어 거울 효과\n",
    "\n",
    "        # 수집할 동작을 표시하는 메시지 출력\n",
    "        cv2.putText(img, f'Waiting for collecting {action.upper()} action...', \n",
    "                    org=(10, 30), fontFace=cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    fontScale=1, color=(255, 255, 255), thickness=2)\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(3000) # 데이터 수집 시작 전에 3초 대기\n",
    "\n",
    "        start_time = time.time() # 시작 시간 기록\n",
    "        \n",
    "        # 지정된 기간 동안 데이터 수집\n",
    "        while time.time() - start_time < secs_for_action:\n",
    "            ret, img = cap.read()\n",
    "\n",
    "            img = cv2.flip(img, 1) # 이미지를 좌우로 뒤집음\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # 이미지를 RGB로 변환\n",
    "            result = hands.process(img) # 이미지를 처리하여 손 검출\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) # 이미지를 BRG로 다시 변환\n",
    "        \n",
    "            # 이미지에서 손이 검출된 경우\n",
    "            if result.multi_hand_landmarks is not None:\n",
    "                for res in result.multi_hand_landmarks:\n",
    "                    joint = np.zeros((21, 4)) # 관절 좌표를 저장할 배열 초기화\n",
    "                    for j, lm in enumerate(res.landmark):\n",
    "                        joint[j] = [lm.x, lm.y, lm.z, lm.visibility]\n",
    "\n",
    "                    # 관절 간의 각도 계산\n",
    "                    v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19], :3] # Parent joint\n",
    "                    v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], :3] # Child joint\n",
    "                    v = v2 - v1 # [20, 3] # 관절 간의 벡터\n",
    "                    v = v / np.linalg.norm(v, axis=1)[:, np.newaxis] # 벡터 정규화\n",
    "\n",
    "                    # 내적의 아크 코사인을 사용하여 각도 계산\n",
    "                    angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                        v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], \n",
    "                        v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])) # [15,]\n",
    "                                        \n",
    "                    angle = np.degrees(angle) # 라디안을 각도로 변환\n",
    "                    \n",
    "                    # 각도와 동작 인덱스를 데이터에 추가\n",
    "                    angle_label = np.array([angle], dtype=np.float32)\n",
    "                    angle_label = np.append(angle_label, idx)\n",
    "\n",
    "                    d = np.concatenate([joint.flatten(), angle_label])\n",
    "\n",
    "                    data.append(d)\n",
    "                    \n",
    "                    # 이미지에 손 랜드마크 그리기\n",
    "                    mp_drawing.draw_landmarks(img, res, mp_hands.HAND_CONNECTIONS)\n",
    "            \n",
    "            # 손 랜드마크가 그려진 이미지 표시\n",
    "            cv2.imshow('img', img)\n",
    "            if cv2.waitKey(1) == ord('q'): # 'q' 키를 누르면 종료\n",
    "                break\n",
    "\n",
    "        # 원시 데이터 저장\n",
    "        data = np.array(data)\n",
    "        print(action, data.shape)\n",
    "        np.save(os.path.join('dataset', f'raw_{action}_{created_time}'), data)\n",
    "\n",
    "        # 원시 데이터에서 시퀀스 데이터 생성\n",
    "        full_seq_data = []\n",
    "        for seq in range(len(data) - seq_length):\n",
    "            full_seq_data.append(data[seq:seq + seq_length])\n",
    "\n",
    "        full_seq_data = np.array(full_seq_data)\n",
    "        print(action, full_seq_data.shape)\n",
    "        np.save(os.path.join('dataset', f'seq_{action}_{created_time}'), full_seq_data)\n",
    "    break # 모든 동작에 대한 데이터 수집 후 while 루프 종료\n",
    "    \n",
    "# 웹캠 해제 및 모든 OpenCV 창 닫기\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# 기존 K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9b0527",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ['good', 'bad', 'four', 'five']\n",
    "# 위의 기존 코드와 동일하게 데이터를 수집합니다.\n",
    "# 수집한 데이터를 'dataset' 디렉토리에 저장합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0804f9e0",
   "metadata": {},
   "source": [
    "# 기존 데이터와 새로운 데이터 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ade0a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 기존 데이터 로드\n",
    "existing_actions = ['one', 'two', 'three']\n",
    "existing_data = []\n",
    "for action in existing_actions:\n",
    "    seq_data = np.load(f'dataset/seq_{action}_{created_time}.npy')\n",
    "    existing_data.append(seq_data)\n",
    "\n",
    "existing_data = np.concatenate(existing_data, axis=0)\n",
    "\n",
    "# 새로운 데이터 로드\n",
    "new_actions = ['good', 'bad', 'four', 'five']\n",
    "new_data = []\n",
    "for action in new_actions:\n",
    "    seq_data = np.load(f'dataset/seq_{action}_{created_time}.npy')\n",
    "    new_data.append(seq_data)\n",
    "\n",
    "new_data = np.concatenate(new_data, axis=0)\n",
    "\n",
    "# 기존 데이터와 새로운 데이터 병합\n",
    "total_data = np.concatenate([existing_data, new_data], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc714b3",
   "metadata": {},
   "source": [
    "# 모델 확장 및 재학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00160be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 기존 모델 로드\n",
    "model = load_model('models/model.keras')\n",
    "\n",
    "# 입력 데이터와 레이블 준비\n",
    "X = total_data[:, :, :-1]\n",
    "y = total_data[:, 0, -1]\n",
    "\n",
    "# 원-핫 인코딩\n",
    "y = to_categorical(y, num_classes=len(existing_actions) + len(new_actions))\n",
    "\n",
    "# 모델 재학습\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=10, batch_size=32)\n",
    "\n",
    "# 모델 저장\n",
    "model.save('models/model.keras')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
